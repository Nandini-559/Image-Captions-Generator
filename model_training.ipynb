{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fdabda92e6747af81a7f71501583be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_001af71188044d97af2eea9c7cf2b1d3",
              "IPY_MODEL_1ebecefe3665460b9def997bb301e516",
              "IPY_MODEL_12f3e4ef4dd34cccba73b4317a39e89c"
            ],
            "layout": "IPY_MODEL_416ff298e9fa472b91914c988ce66eab"
          }
        },
        "001af71188044d97af2eea9c7cf2b1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73c89f718f549d79bb495492ddeb406",
            "placeholder": "​",
            "style": "IPY_MODEL_7270fd64270845c0a645f51c43841928",
            "value": "100%"
          }
        },
        "1ebecefe3665460b9def997bb301e516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f02fad4a8e4d02baff1edbb78432d0",
            "max": 8091,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c3c99e457e043e9989a62d71c257ff4",
            "value": 8091
          }
        },
        "12f3e4ef4dd34cccba73b4317a39e89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee24a6325314f189b270db8fcd29350",
            "placeholder": "​",
            "style": "IPY_MODEL_a63d8de5a1b541f6b3bce612e9e6fff9",
            "value": " 8091/8091 [2:14:22&lt;00:00,  1.11s/it]"
          }
        },
        "416ff298e9fa472b91914c988ce66eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73c89f718f549d79bb495492ddeb406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7270fd64270845c0a645f51c43841928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04f02fad4a8e4d02baff1edbb78432d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3c99e457e043e9989a62d71c257ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ee24a6325314f189b270db8fcd29350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63d8de5a1b541f6b3bce612e9e6fff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSRXxZxZ5e3p",
        "outputId": "2c070c10-c647-4bf2-ab65-ffc0a569dbbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from concurrent.futures import ProcessPoolExecutor  # For parallel processing\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
        "from tensorflow.keras.utils import to_categorical, plot_model"
      ],
      "metadata": {
        "id": "uXIui2bG6RvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/COLAB/Image_Caption_Generator/Dataset'  # Update this to your local directory\n",
        "WORKING_DIR = '/content/drive/MyDrive/COLAB/Image_Caption_Generator/Working'  # Update this to your local directory"
      ],
      "metadata": {
        "id": "AaTgfCwf6UUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Image Features\n",
        "# Load VGG19 Model\n",
        "model = VGG19(weights='/content/drive/MyDrive/COLAB/Image_Caption_Generator/Working/vgg19_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "# Restructure model\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "I-Kz6PjN6pBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d21bf9b-11c4-410a-90e2-4629aafe7191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139570240 (532.42 MB)\n",
            "Trainable params: 139570240 (532.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = {}\n",
        "directory = os.path.join(BASE_DIR, 'Images')\n",
        "\n",
        "for img_name in tqdm(os.listdir(directory)):\n",
        "    # Load the image from file\n",
        "    img_path = os.path.join(directory, img_name)\n",
        "    image = load_img(img_path, target_size=(224, 224))\n",
        "    # Convert image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # Reshape data for the model\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    # Preprocess image for VGG19\n",
        "    image = preprocess_input(image)\n",
        "    # Extract features\n",
        "    feature = model.predict(image, verbose=0)\n",
        "    # Get image ID\n",
        "    image_id = img_name.split('.')[0]\n",
        "    # Store feature\n",
        "    features[image_id] = feature\n"
      ],
      "metadata": {
        "id": "R91feN247A5D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6fdabda92e6747af81a7f71501583be5",
            "001af71188044d97af2eea9c7cf2b1d3",
            "1ebecefe3665460b9def997bb301e516",
            "12f3e4ef4dd34cccba73b4317a39e89c",
            "416ff298e9fa472b91914c988ce66eab",
            "d73c89f718f549d79bb495492ddeb406",
            "7270fd64270845c0a645f51c43841928",
            "04f02fad4a8e4d02baff1edbb78432d0",
            "2c3c99e457e043e9989a62d71c257ff4",
            "3ee24a6325314f189b270db8fcd29350",
            "a63d8de5a1b541f6b3bce612e9e6fff9"
          ]
        },
        "outputId": "5f825ff3-4c20-4225-e38e-4d3e167a4800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8091 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fdabda92e6747af81a7f71501583be5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store features in pickle\n",
        "# with open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb') as f:\n",
        "    # pickle.dump(features, f)"
      ],
      "metadata": {
        "id": "SwzmQqfH94P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load features from pickle\n",
        "with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:\n",
        "    features = pickle.load(f)"
      ],
      "metadata": {
        "id": "eb4NEdTCOjek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(features)"
      ],
      "metadata": {
        "id": "-KcKQ5DIuU-A",
        "outputId": "44161642-421b-4588-f9d7-cb8d08ab512e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8091"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Captions Data\n",
        "with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:\n",
        "    next(f)\n",
        "    captions_doc = f.read()\n",
        "\n",
        "# Now we split and append the captions data with the image\n",
        "# Create mapping of image to captions\n",
        "mapping = {}\n",
        "# Process lines\n",
        "for line in captions_doc.split('\\n'):\n",
        "    # Split the line by comma(,)\n",
        "    tokens = line.split(',')\n",
        "    if len(line) < 2:\n",
        "        continue\n",
        "    image_id, caption = tokens[0], tokens[1:]\n",
        "    # Remove the extension from the image ID\n",
        "    image_id = image_id.split('.')[0]\n",
        "    # Convert caption list to a string\n",
        "    caption = \" \".join(caption)\n",
        "    # Create a list if needed\n",
        "    if image_id not in mapping:\n",
        "        mapping[image_id] = []\n",
        "    # Store the caption\n",
        "    mapping[image_id].append(caption)"
      ],
      "metadata": {
        "id": "mpucNyBo7NDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Text Data\n",
        "def clean(captions_dict):\n",
        "    for key, captions in captions_dict.items():\n",
        "        for i in range(len(captions)):\n",
        "            # Take one caption at a time\n",
        "            caption = captions[i]\n",
        "            # Preprocessing steps\n",
        "            # Convert to lowercase\n",
        "            caption = caption.lower()\n",
        "            # Delete digits, special chars, etc.,\n",
        "            caption = caption.replace('[^A-Za-z]', '')\n",
        "            # Delete additional spaces\n",
        "            caption = caption.replace('\\s+', ' ')\n",
        "            # Add start and end tags to the caption\n",
        "            caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word) > 1]) + ' endseq'\n",
        "            captions[i] = caption\n"
      ],
      "metadata": {
        "id": "YmZ-jMFv7Tbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before preprocess of text\n",
        "print(mapping['1000268201_693b08cb0e'])\n",
        "\n",
        "# Preprocess the text\n",
        "clean(mapping)\n",
        "\n",
        "# After preprocess of text\n",
        "print(mapping['1000268201_693b08cb0e'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZdUetkh7U-z",
        "outputId": "fe259ea5-fbe0-430b-930c-2df071dca4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .', 'A little girl climbing into a wooden playhouse .', 'A little girl climbing the stairs to her playhouse .', 'A little girl in a pink dress going into a wooden cabin .']\n",
            "['startseq child in pink dress is climbing up set of stairs in an entry way endseq', 'startseq girl going into wooden building endseq', 'startseq little girl climbing into wooden playhouse endseq', 'startseq little girl climbing the stairs to her playhouse endseq', 'startseq little girl in pink dress going into wooden cabin endseq']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we will store the preprocessed captions into a list\n",
        "all_captions = []\n",
        "for key in mapping:\n",
        "    for caption in mapping[key]:\n",
        "        all_captions.append(caption)\n",
        "\n",
        "# Processing of Text Data\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_captions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size:\", vocab_size)\n",
        "\n",
        "# Get the maximum length of the caption available\n",
        "max_length = max(len(caption.split()) for caption in all_captions)\n",
        "print(\"Maximum Caption Length:\", max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtqxC5Uo7YlU",
        "outputId": "9edb3541-3721-4eb0-becb-0996a13d35cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 8485\n",
            "Maximum Caption Length: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Tokenns in pickle\n",
        "with open(os.path.join(WORKING_DIR, 'tokenizer.pkl'), 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "DWLrAP6_ztSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Test Split\n",
        "# After preprocessing the data, now we will train, test, and split\n",
        "image_ids = list(mapping.keys())\n",
        "split = int(len(image_ids) * 0.90)\n",
        "train = image_ids[:split]\n",
        "test = image_ids[split:]"
      ],
      "metadata": {
        "id": "aAFCnZ557eqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))\n",
        "print(len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlLyTo7girB6",
        "outputId": "1bd26fb8-b808-49e5-a030-32595e817512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7281\n",
            "810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data generator to get data in batches (avoids session crash)\n",
        "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
        "    while True:\n",
        "        X1, X2, y = [], [], []\n",
        "        n = 0\n",
        "        for key in data_keys:\n",
        "            n += 1\n",
        "            captions = mapping[key]\n",
        "            # Process each caption\n",
        "            for caption in captions:\n",
        "                # Encode the sequence\n",
        "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "                # Split the sequence into X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # Split into input and output pairs\n",
        "                    in_seq, out_seq = seq[:i], seq[i]\n",
        "                    # Pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # Encode output sequence\n",
        "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "                    # Store the sequences\n",
        "                    X1.append(features[key][0])\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq)\n",
        "                if n == batch_size:\n",
        "                    yield [[np.array(X1), np.array(X2)], np.array(y)]\n",
        "                    X1, X2, y = [], [], []\n",
        "                    n = 0"
      ],
      "metadata": {
        "id": "0fQ2-I837hc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Creation\n",
        "# Encoder model\n",
        "# Image feature layers\n",
        "inputs1 = Input(shape=(4096,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "# Sequence feature layers\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "\n",
        "# Decoder model\n",
        "decoder1 = add([fe2, se3])\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Plot the model\n",
        "#plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "lH3fWuIWKCTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "# Train the model\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "steps = len(train) // batch_size\n",
        "\n",
        "for i in range(epochs):\n",
        "    # Create a data generator\n",
        "    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "    # Fit for one epoch\n",
        "\n",
        "    history = model.fit(generator, steps_per_epoch=steps, verbose=1)\n",
        "\n",
        "    # Print loss and accuracy\n",
        "    print(\"Epoch\", i + 1,\" Loss:\", history.history['loss'][0])\n",
        "\n",
        "\n",
        "# You can save the model in the working directory for reuse\n",
        "# Save the model\n",
        "# model.save(os.path.join(WORKING_DIR, 'best_model.h5'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJiTtXMHP9Ed",
        "outputId": "e099b7c2-a6a4-48c1-cc4e-f4217cf78e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "227/227 [==============================] - 1199s 5s/step - loss: 4.8971\n",
            "Epoch 1  Loss: 4.897119998931885\n",
            "227/227 [==============================] - 1190s 5s/step - loss: 3.9236\n",
            "Epoch 2  Loss: 3.923624038696289\n",
            "227/227 [==============================] - 1180s 5s/step - loss: 3.5434\n",
            "Epoch 3  Loss: 3.543384075164795\n",
            "227/227 [==============================] - 1172s 5s/step - loss: 3.2961\n",
            "Epoch 4  Loss: 3.296121597290039\n",
            "227/227 [==============================] - 1172s 5s/step - loss: 3.1070\n",
            "Epoch 5  Loss: 3.1069700717926025\n",
            "227/227 [==============================] - 1161s 5s/step - loss: 2.9640\n",
            "Epoch 6  Loss: 2.963958740234375\n",
            "227/227 [==============================] - 1156s 5s/step - loss: 2.8525\n",
            "Epoch 7  Loss: 2.8525118827819824\n",
            "227/227 [==============================] - 1132s 5s/step - loss: 2.7594\n",
            "Epoch 8  Loss: 2.759397029876709\n",
            "227/227 [==============================] - 1101s 5s/step - loss: 2.6825\n",
            "Epoch 9  Loss: 2.6825435161590576\n",
            "227/227 [==============================] - 1250s 6s/step - loss: 2.6146\n",
            "Epoch 10  Loss: 2.614645481109619\n",
            "227/227 [==============================] - 1207s 5s/step - loss: 2.5580\n",
            "Epoch 11  Loss: 2.5580403804779053\n",
            "227/227 [==============================] - 1213s 5s/step - loss: 2.5095\n",
            "Epoch 12  Loss: 2.509533643722534\n",
            "227/227 [==============================] - 1210s 5s/step - loss: 2.4631\n",
            "Epoch 13  Loss: 2.46307110786438\n",
            "227/227 [==============================] - 1214s 5s/step - loss: 2.4248\n",
            "Epoch 14  Loss: 2.424828052520752\n",
            "227/227 [==============================] - 1203s 5s/step - loss: 2.3888\n",
            "Epoch 15  Loss: 2.3888487815856934\n",
            "227/227 [==============================] - 1213s 5s/step - loss: 2.3547\n",
            "Epoch 16  Loss: 2.3546574115753174\n",
            "227/227 [==============================] - 1207s 5s/step - loss: 2.3193\n",
            "Epoch 17  Loss: 2.319345474243164\n",
            "227/227 [==============================] - 1224s 5s/step - loss: 2.2866\n",
            "Epoch 18  Loss: 2.286574602127075\n",
            "227/227 [==============================] - 1204s 5s/step - loss: 2.2581\n",
            "Epoch 19  Loss: 2.258127450942993\n",
            "227/227 [==============================] - 1195s 5s/step - loss: 2.2310\n",
            "Epoch 20  Loss: 2.2309975624084473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_time : 24376.641498088837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(os.path.join(WORKING_DIR, 'best_model.h5'))\n",
        "\n",
        "# Load tokenizer from pickle\n",
        "with open(os.path.join(WORKING_DIR, 'tokenizer.pkl'), 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ],
      "metadata": {
        "id": "LejdFnFY0Utm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}