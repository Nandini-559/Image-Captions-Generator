{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTE9KvQgWOUu",
        "outputId": "2cc9f013-4fe0-43d6-8c99-b162f054be0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o2FNHYjWYEqn"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'distutils'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_img\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n",
            "File \u001b[1;32mc:\\Users\\Queen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_inspect\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input,VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE2cu9e9hZvB"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = '/content/drive/MyDrive/COLAB/working'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhUxG2laaJ-A"
      },
      "outputs": [],
      "source": [
        "# Load features from pickle\n",
        "with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:\n",
        "    features = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "6_oEfBE4lwNa",
        "outputId": "b0980275-c576-4a8b-f653-eb084f7e0960"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(WORKING_DIR, 'tokenizer.pkl'), 'rb') as t:\n",
        "    tokenizer = pickle.load(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIV8M9u5hNIq"
      },
      "outputs": [],
      "source": [
        "# Extract Image Features\n",
        "# Load VGG19 Model\n",
        "model = VGG19(weights=os.path.join(WORKING_DIR, 'vgg19_weights_tf_dim_ordering_tf_kernels.h5'))\n",
        "\n",
        "# Restructure model\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_ZCAlwe6uVQ"
      },
      "outputs": [],
      "source": [
        "# Path to the model file in Google Drive\n",
        "model_path = os.path.join(WORKING_DIR, 'best_model.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3vy7FGe9kYD"
      },
      "outputs": [],
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFzZqRuqYIWH"
      },
      "outputs": [],
      "source": [
        "# Preprocess the new image\n",
        "# Assume 'new_image' is the dynamic image\n",
        "# Preprocess the image\n",
        "'''new_image = load_img(new_image_path, target_size=(224, 224))\n",
        "new_image = img_to_array(new_image)\n",
        "new_image = new_image.reshape((1, new_image.shape[0], new_image.shape[1], new_image.shape[2]))\n",
        "new_image = preprocess_input(new_image)\n",
        "\n",
        "# Extract features using the pre-trained model\n",
        "new_feature = model.predict(new_image, verbose=0)'''\n",
        "\n",
        "# Define a function to generate captions for dynamic images\n",
        "def generate_caption(model, tokenizer, max_length, image_feature):\n",
        "    in_text = 'startseq'\n",
        "    for _ in range(max_length):\n",
        "        # Encode input sequence\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        # Predict next word\n",
        "        yhat = model.predict([image_feature, sequence], verbose=0)\n",
        "        # Convert probability to integer\n",
        "        yhat = np.argmax(yhat)\n",
        "        # Map integer to word\n",
        "        word = word_for_id(yhat, tokenizer)\n",
        "        # Stop if we cannot map the word\n",
        "        if word is None:\n",
        "            break\n",
        "        # Append as input for generating the next word\n",
        "        in_text += ' ' + word\n",
        "        # Stop if we predict the end of the sequence\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-kPDBm0nIZc"
      },
      "outputs": [],
      "source": [
        "def image_feature(new_image_path,model):\n",
        "  new_image = load_img(new_image_path, target_size=(224, 224))\n",
        "  new_image = img_to_array(new_image)\n",
        "  new_image = new_image.reshape((1, new_image.shape[0], new_image.shape[1], new_image.shape[2]))\n",
        "  new_image = preprocess_input(new_image)\n",
        "\n",
        "  # Extract features using the pre-trained model\n",
        "  new_feature = model.predict(new_image, verbose=0)\n",
        "  return new_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWaV2BL3t5QW"
      },
      "outputs": [],
      "source": [
        "image_path = os.path.join(WORKING_DIR, 'image2.jpg')\n",
        "new_feature = image_feature(image_path, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPRHaM2O90fR",
        "outputId": "38d492fb-abfb-4ac7-b9f0-43e0534d30d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "startseq person skiing down snowy mountain endseq\n"
          ]
        }
      ],
      "source": [
        "#Generate caption for the new image\n",
        "caption = generate_caption(loaded_model, tokenizer, 35, new_feature)\n",
        "print(caption)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
